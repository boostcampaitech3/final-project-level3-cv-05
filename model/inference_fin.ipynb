{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import argparse\n",
    "import torch \n",
    "import pytorch_lightning as pl\n",
    "import json\n",
    "import random\n",
    "import yaml\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import torchvision.transforms as transform\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ipywidgets import interact\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from munch import Munch\n",
    "from PIL import Image\n",
    "\n",
    "from model import PostOCRLearner\n",
    "from dataset import PostOCRDataLoader\n",
    "import feature_engineering\n",
    "\n",
    "from ipywidgets import interact\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import *\n",
    "import pandas as pd\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Test 이미지 Resize , OCR api requests , Bbox 합치기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01. Test 이미지 Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = sorted(os.listdir('/opt/final-project-level3-cv05/model/image_test'))\n",
    "\n",
    "for img in files:\n",
    "    if img != '.DS_Store': \n",
    "        im=os.path.join('/opt/final-project-level3-cv05/model/image_test',img)\n",
    "        ims=cv2.imread(im)\n",
    "        if ims is None:\n",
    "            continue\n",
    "        resize_img=cv2.resize(ims,(900,500))\n",
    "        cv2.imwrite(f'test_image/{img}',resize_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02. OCR api requests & Bbox 합치기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import requests\n",
    "\n",
    "from word2line import word2line\n",
    "\n",
    "def api(img):\n",
    "    api_url = \"http://118.222.179.32:30000/ocr/\"\n",
    "    headers = {\"secret\": \"Boostcamp0000\"}\n",
    "    file_dict = {\"file\": open(img, \"rb\")}\n",
    "    response = requests.post(api_url, headers=headers, files=file_dict)\n",
    "    response_json=response.json()\n",
    "    return response_json\n",
    "    \n",
    "with open('sample.json', 'r', encoding=\"UTF-8\") as j:\n",
    "    json_object = json.load(j)\n",
    "\n",
    "files = sorted(os.listdir('/opt/final-project-level3-cv05/model/test_image'))\n",
    "\n",
    "for idx, img in enumerate(files):\n",
    "    response_json=api(os.path.join('/opt/final-project-level3-cv05/model/test_image',img))\n",
    "    # bbox 병합 코드 -> json\n",
    "    json_object[\"images\"].append({\"width\": 900, \"height\": 500, \"file\":img, \"id\": idx})\n",
    "    annotation = {\"image_id\":idx, \"ocr\":{\"word\":response_json['ocr']['word']}}\n",
    "    line_annotation = word2line(annotation)\n",
    "    json_object[\"annotations\"].append(line_annotation)\n",
    "\n",
    "with open('info_test.json', 'w', encoding=\"UTF-8\") as j:\n",
    "    json_string = json.dump(json_object,j, indent=2,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "    with open('/opt/final-project-level3-cv05/model/config_inference.yaml', 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    return Munch(cfg)\n",
    "\n",
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d13478e57df45db9e928297064f9a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = config()\n",
    "datamodule = PostOCRDataLoader(cfg, **cfg.Dataset)\n",
    "test_model = PostOCRLearner(cfg)\n",
    "\n",
    "best_model = '/opt/final-project-level3-cv05/model/boostcamp3_cv_final_ocr/pmucsaka/checkpoints/epoch=8_val_accuracy=0.9789.ckpt'\n",
    "model=test_model.load_from_checkpoint(best_model,cfg=cfg)\n",
    "\n",
    "trainer = pl.Trainer(**cfg.trainer)\n",
    "pred=trainer.predict(model, dataloaders=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_categoryid=[]\n",
    "\n",
    "model_pred_lst=[]\n",
    "small_pred_lst=[]\n",
    "for i in pred:\n",
    "        # criterion = torch.nn.Softmax()\n",
    "# prob = criterion(out)\n",
    "        softmax=torch.nn.functional.softmax(i['pred'],dim=1,dtype=torch.float)\n",
    "        \n",
    "        prd = softmax.cpu().detach().numpy()\n",
    "        # prd,idx = torch.max(prd,dim=1)\n",
    "\n",
    "        # small_pred_lst.append([prd,idx])\n",
    "        small_pred_lst.append(prd[0])\n",
    "\n",
    "# small_pred_lst\n",
    "model_pred_lst.append(np.array(small_pred_lst)[...,np.newaxis])\n",
    "model_pred_lst\n",
    "pred_categoryid.append(np.argmax(np.mean(np.concatenate(model_pred_lst, axis=2), axis=2), axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0,  5,  8,  5,  0,  6,  0,  6,  3,  0,  8, 10,  5,  5,  7,  5, 10])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_categoryid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ccfcac85c84e29934c871db321088c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx', max=0), Dropdown(description='cls_id', index=11, o…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "categories = {\n",
    "            \"0\": \"UNKNOWN\",\n",
    "            \"1\": \"name\",\n",
    "            \"2\": \"phone\",\n",
    "            \"3\": \"email\",\n",
    "            \"4\": \"position\",\n",
    "            \"5\": \"company\",\n",
    "            \"6\": \"department\",\n",
    "            \"7\": \"address\",\n",
    "            \"8\": \"site\",\n",
    "            \"9\": \"account\",\n",
    "            \"10\": \"wise\",\n",
    "        }\n",
    "\n",
    "root_path = 'test_image' # images folder \n",
    "anno_root = 'info_test.json' # json file folder\n",
    "\n",
    "with open(anno_root, 'r') as f:\n",
    "    train_json = json.load(f)\n",
    "    images = train_json['images']\n",
    "    annotations = train_json['annotations']\n",
    "\n",
    "images_viz = dict()\n",
    "for idx, item in enumerate(images):\n",
    "    images_viz[item['id']] = dict()\n",
    "    images_viz[item['id']]['id'] = item['id']\n",
    "    images_viz[item['id']]['file_name'] = item['file']\n",
    "    images_viz[item['id']]['category_id'] = list(pred_categoryid[0])\n",
    "\n",
    "for anno in annotations:\n",
    "    images_viz[anno['image_id']]['bbox'] = anno['ocr']['word']\n",
    "\n",
    "palette = sns.color_palette('bright',11)\n",
    "\n",
    "fnames = [(images_viz[id]['id'], images_viz[id]['file_name']) for id in images_viz]\n",
    "\n",
    "@interact(idx=(fnames[0][0], fnames[-1][0]), cls_id=range(0, len(categories)+1))\n",
    "def showImg(idx=0, cls_id=len(categories)):\n",
    "    fig, ax = plt.subplots(dpi=200)\n",
    "    img = io.imread(root_path + '/' +fnames[idx][1])\n",
    "\n",
    "    anns = images_viz[idx]['bbox']\n",
    "    category_ids=images_viz[idx]['category_id']\n",
    "\n",
    "    ax.imshow(img)\n",
    "    for i, ann in enumerate(anns):\n",
    "\n",
    "        class_idx = category_ids[i]\n",
    "\n",
    "        ax.set_title(f\"{fnames[idx][1]}\", fontsize=7)\n",
    "\n",
    "        # 축 제거 \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        for pos in ['right', 'top', 'bottom', 'left']:\n",
    "            ax.spines[pos].set_visible(False)\n",
    "\n",
    "        points = np.array(ann['points'])\n",
    "        text = ann['text']\n",
    "\n",
    "        # bbox 시각화 \n",
    "        if(class_idx == cls_id or cls_id == 11):\n",
    "            color = palette[class_idx]\n",
    "            ax.add_patch(\n",
    "                patches.Polygon(\n",
    "                    points,\n",
    "                    closed=True,\n",
    "                    edgecolor=color,\n",
    "                    fill=False,\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "            x, y = points[-1][0], points[0][1]\n",
    "\n",
    "            text_y = y-5 if y>5 else y+5 \n",
    "            plt_text = ax.text(x,text_y, f'{class_idx} : {categories[str(class_idx)]}', color='white', fontsize='3', weight='semibold', backgroundcolor=color)\n",
    "            plt_text.set_bbox(dict(\n",
    "                facecolor=palette[class_idx],  # background color\n",
    "                alpha=0.6,  # background alpha\n",
    "                edgecolor='none',  # border color\n",
    "                pad=2\n",
    "            ))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
